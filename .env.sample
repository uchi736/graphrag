# Graph Backend Configuration
# グラフデータベースのバックエンド選択
# "neo4j" = Neo4j Aura/Server (推奨: 大規模データ、高度なクエリ)
# "networkx" = NetworkX (推奨: 軽量、Neo4j不要、小〜中規模データ)
GRAPH_BACKEND=networkx

# Neo4j Configuration (GRAPH_BACKEND=neo4j の場合のみ必要)
# Neo4j Auraの接続情報
# 例: neo4j+s://xxxxx.databases.neo4j.io
NEO4J_URI=neo4j+s://your-instance-id.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PW=your_neo4j_password

# PostgreSQL Configuration
# PGVector拡張がインストールされたPostgreSQLの接続文字列
# 例: postgresql+psycopg://user:password@host:port/database
PG_CONN=postgresql+psycopg://postgres:your_password@your-host:5432/postgres
# コレクション名（他プログラムとの衝突防止）
# 例: PG_COLLECTION=myapp → "myapp", "myapp_entities"
PG_COLLECTION=graphrag

# Azure OpenAI Service Settings
# Azure OpenAIの接続情報
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=text-embedding-3-small

# Azure Document Intelligence Configuration (Optional)
# PDFの高精度解析（テーブル、レイアウト保持、OCR）
# 設定しない場合はPyMuPDFを使用
AZURE_DI_ENDPOINT=https://your-di-resource.cognitiveservices.azure.com
AZURE_DI_API_KEY=your_document_intelligence_api_key
# モデル: prebuilt-layout (推奨), prebuilt-read, prebuilt-document
AZURE_DI_MODEL=prebuilt-layout

# Knowledge Graph Configuration
# ナレッジグラフ設定
# true = エンティティと関係性を抽出してグラフ構造を生成（高度な推論可能）
# false = ベクトル検索のみ使用（高速処理）
ENABLE_KNOWLEDGE_GRAPH=true

# Entity Vector Search Configuration
# エンティティベクトル検索設定
# true = エンティティの類似度検索を有効化（類義語や関連語も検索）
# false = キーワードマッチングのみ使用
ENABLE_ENTITY_VECTOR_SEARCH=true
# エンティティ検索の類似度閾値（0.5-1.0、デフォルト: 0.7）
# 低いほど幅広く検索、高いほど厳密に検索
ENTITY_SIMILARITY_THRESHOLD=0.7

# Japanese Hybrid Search Configuration
# 日本語ハイブリッド検索の設定
# ベクトル検索とキーワード検索をRRFで統合（精度向上）
ENABLE_JAPANESE_SEARCH=true
# 最小トークン長（1文字のトークンを除外）
JAPANESE_MIN_TOKEN_LENGTH=2

# Retrieval Configuration
# 検索設定
# RAG検索で取得するチャンク数（1-20、デフォルト: 5）
# 多いほど文脈が豊富になりますが、処理時間が増加します
RETRIEVAL_TOP_K=5

# Graph Hop Count Configuration
# グラフ探索ホップ数（1-3、デフォルト: 1）
# 1hop=直接関係のみ、2hop=友達の友達まで、3hop=さらに間接的な関係まで探索
GRAPH_HOP_COUNT=1

# LLM Provider Configuration
# LLMプロバイダー設定
# "azure_openai" = Azure OpenAI Service (デフォルト)
# "vllm" = VLLM Server (セルフホステッドモデル)
LLM_PROVIDER=azure_openai

# VLLM Configuration (LLM_PROVIDER=vllm の場合のみ必要)
# VLLMサーバーの設定
# エンドポイントURL（末尾に /v1 を含める）
VLLM_ENDPOINT=https://your-vllm-server.example.com/v1
# 生成パラメータ
VLLM_TEMPERATURE=0.0
VLLM_TOP_P=0.7
VLLM_TOP_K=5
VLLM_MIN_P=0.0
VLLM_MAX_TOKENS=4096
VLLM_REASONING_EFFORT=medium
# タイムアウト設定（秒）
VLLM_TIMEOUT=60
