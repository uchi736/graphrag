"""
Streamlit UI for Graph-RAG
===========================
ã‚·ãƒ³ãƒ—ãƒ«ãªGraph-RAGç”¨ã®Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- PDF/ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- è³ªå•å…¥åŠ›ã¨RAGå®Ÿè¡Œ
- ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã®å¯è¦–åŒ–
"""
import os
import streamlit as st
from pathlib import Path
from dotenv import load_dotenv
import tempfile
from typing import List

# LangChain imports
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_experimental.text_splitter import SemanticChunker
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_community.graphs import Neo4jGraph
from langchain_community.document_loaders import PyPDFLoader, TextLoader
try:
    from langchain_community.graphs.graph_document import GraphDocument
except ImportError:
    from langchain_community.graphs import GraphDocument
from langchain_community.vectorstores.pgvector import PGVector

try:
    from langchain_community.retrievers.graph import GraphRetriever
except ImportError:
    try:
        from langchain_graph_retriever import GraphRetriever
    except ImportError:
        from langchain_graph_retriever.graph_retriever import GraphRetriever

try:
    from langchain_community.retrievers.parent_document import ParentDocumentRetriever
    HAS_PARENT = True
except ImportError:
    try:
        from langchain.retrievers.parent_document import ParentDocumentRetriever
        HAS_PARENT = True
    except ImportError:
        HAS_PARENT = False

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import (
    RunnableParallel,
    RunnablePassthrough,
    RunnableLambda,
)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# Streamlitè¨­å®š
st.set_page_config(
    page_title="Graph-RAG Demo",
    page_icon="ğŸ”—",
    layout="wide"
)

st.title("ğŸ”— Graph-RAG with Neo4j & PGVector")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: ç’°å¢ƒè¨­å®šç¢ºèª
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")

    AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
    AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
    AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
    AZURE_OPENAI_CHAT_DEPLOYMENT = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME")
    AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
    NEO4J_URI = os.getenv("NEO4J_URI")
    NEO4J_USER = os.getenv("NEO4J_USER")
    NEO4J_PW = os.getenv("NEO4J_PW")
    PG_CONN = os.getenv("PG_CONN")

    if not all([AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, NEO4J_URI, NEO4J_USER, NEO4J_PW, PG_CONN]):
        st.error("ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success("âœ… ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿å®Œäº†")

    st.markdown("---")
    st.markdown("### ğŸ“Š ã‚°ãƒ©ãƒ•å¯è¦–åŒ–è¨­å®š")

    viz_engine = st.radio(
        "å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³",
        ["Streamlit-Agraph (æ¨å¥¨)", "Pyvis (è©³ç´°)"],
        index=0,
        help="Agraphã¯è»½é‡ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã€Pyvisã¯ã‚ˆã‚Šè©³ç´°ãªè¨­å®šãŒå¯èƒ½"
    )

    show_graph = st.checkbox("ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º", value=True)

    if show_graph:
        max_nodes = st.slider("æœ€å¤§è¡¨ç¤ºãƒãƒ¼ãƒ‰æ•°", 50, 500, 200, 50)

        st.markdown("**ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼**")
        filter_person = st.checkbox("ğŸ‘¤ äººç‰© (Person)", value=True)
        filter_place = st.checkbox("ğŸï¸ å ´æ‰€ (Place)", value=True)
        filter_event = st.checkbox("âš¡ ã‚¤ãƒ™ãƒ³ãƒˆ (Event)", value=True)
        filter_object = st.checkbox("ğŸ“¦ ç‰© (Object)", value=True)
        filter_other = st.checkbox("â“ ãã®ä»– (Other)", value=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if "chain" not in st.session_state:
    st.session_state.chain = None
if "graph" not in st.session_state:
    st.session_state.graph = None
if "initialized" not in st.session_state:
    st.session_state.initialized = False
if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []
if "existing_graph_loaded" not in st.session_state:
    st.session_state.existing_graph_loaded = False

# Neo4jæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯é–¢æ•°
def check_existing_graph(graph) -> dict:
    """Neo4jã«æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    try:
        query = """
        MATCH (n)
        RETURN count(n) AS node_count
        """
        result = graph.query(query)
        node_count = result[0]['node_count'] if result else 0

        if node_count > 0:
            # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒƒãƒ—ã‚‚ã‚«ã‚¦ãƒ³ãƒˆ
            query_rel = """
            MATCH ()-[r]->()
            RETURN count(r) AS rel_count
            """
            result_rel = graph.query(query_rel)
            rel_count = result_rel[0]['rel_count'] if result_rel else 0

            return {
                'exists': True,
                'node_count': node_count,
                'rel_count': rel_count
            }
        return {'exists': False, 'node_count': 0, 'rel_count': 0}
    except Exception as e:
        st.error(f"Neo4jæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return {'exists': False, 'node_count': 0, 'rel_count': 0}

# æ—¢å­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ã‚’å¾©å…ƒ
def restore_from_existing_graph():
    """Neo4jã¨PGVectorã‹ã‚‰æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã‚·ã‚¹ãƒ†ãƒ ã‚’å¾©å…ƒ"""
    try:
        # Neo4jæ¥ç¶š
        graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PW)

        # PGVectoræ¥ç¶š
        embeddings = AzureOpenAIEmbeddings(
            azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,
            openai_api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY
        )
        vector_store = PGVector(
            connection_string=PG_CONN,
            embedding_function=embeddings
        )

        # Vector Retrieveræ§‹ç¯‰
        if HAS_PARENT:
            vector_retriever = ParentDocumentRetriever(vector_store, search_kwargs={"k": 4})
        else:
            vector_retriever = vector_store.as_retriever(search_kwargs={"k": 4})

        # ã‚°ãƒ©ãƒ•æ¤œç´¢é–¢æ•°
        def get_graph_context(question: str) -> list:
            query = """
            MATCH (n)-[r]->(m)
            RETURN n.id AS start, type(r) AS type, m.id AS end
            LIMIT 10
            """
            try:
                result = graph.query(query)
                return result if result else []
            except Exception:
                return []

        # ãƒã‚§ã‚¤ãƒ³æ§‹ç¯‰
        def retriever_and_merge(question: str):
            docs = vector_retriever.invoke(question)
            triples = get_graph_context(question)

            graph_lines = [
                f"{t.get('start')} -[{t.get('type')}]â†’ {t.get('end')}"
                for t in triples
            ] if triples else ["(ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãªã—)"]

            context = (
                "<GRAPH_CONTEXT>\n" + "\n".join(graph_lines) + "\n</GRAPH_CONTEXT>\n\n" +
                "<DOCUMENT_CONTEXT>\n" + "\n---\n".join(d.page_content for d in docs) + "\n</DOCUMENT_CONTEXT>"
            )
            return {"context": context, "question": question}

        prompt = PromptTemplate.from_template(
            """ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚\nè³ªå•: {question}\n\n{context}\n\n---\nä¸Šè¨˜æƒ…å ±ã®ã¿ã‚’æ ¹æ‹ ã«ã€æ—¥æœ¬èªã§ç¶²ç¾…çš„ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
        )

        chain = (
            RunnablePassthrough()
            | RunnableLambda(retriever_and_merge)
            | prompt
            | AzureChatOpenAI(
                azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT,
                openai_api_version=AZURE_OPENAI_API_VERSION,
                azure_endpoint=AZURE_OPENAI_ENDPOINT,
                api_key=AZURE_OPENAI_API_KEY,
                temperature=0
            )
            | StrOutputParser()
        )

        return chain, graph

    except Exception as e:
        raise Exception(f"ã‚·ã‚¹ãƒ†ãƒ å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿é–¢æ•°
def load_documents(uploaded_files) -> str:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    all_text = []

    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name

        try:
            if uploaded_file.name.endswith('.pdf'):
                loader = PyPDFLoader(tmp_path)
                docs = loader.load()
                all_text.append("\n".join([doc.page_content for doc in docs]))
            elif uploaded_file.name.endswith('.txt'):
                loader = TextLoader(tmp_path, encoding='utf-8')
                docs = loader.load()
                all_text.append("\n".join([doc.page_content for doc in docs]))
            else:
                # ãã®ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
                text = uploaded_file.getvalue().decode('utf-8')
                all_text.append(text)
        finally:
            os.unlink(tmp_path)

    return "\n\n".join(all_text)

# åˆæœŸåŒ–é–¢æ•°
def build_rag_system(text_content: str):
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰"""

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    embeddings = AzureOpenAIEmbeddings(
        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,
        openai_api_version=AZURE_OPENAI_API_VERSION,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY
    )
    chunker = SemanticChunker(embeddings, buffer_size=50)
    chunks = chunker.create_documents([text_content])

    # GraphDocumentåŒ–
    llm = AzureChatOpenAI(
        azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT,
        openai_api_version=AZURE_OPENAI_API_VERSION,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        temperature=0
    )
    transformer = LLMGraphTransformer(llm=llm)
    graph_docs = transformer.convert_to_graph_documents(chunks)

    # Neo4jãƒ­ãƒ¼ãƒ‰
    graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PW)
    graph.add_graph_documents(graph_docs, include_source=True)

    # PGVectorä¿å­˜
    vector_store = PGVector.from_documents(chunks, embeddings, connection_string=PG_CONN)

    # Vector Retrieveræ§‹ç¯‰
    if HAS_PARENT:
        vector_retriever = ParentDocumentRetriever(vector_store, search_kwargs={"k": 4})
    else:
        vector_retriever = vector_store.as_retriever(search_kwargs={"k": 4})

    # ã‚°ãƒ©ãƒ•æ¤œç´¢é–¢æ•°ï¼ˆCypherç›´æ¥å®Ÿè¡Œï¼‰
    def get_graph_context(question: str) -> list:
        """Neo4jã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        query = """
        MATCH (n)-[r]->(m)
        RETURN n.id AS start, type(r) AS type, m.id AS end
        LIMIT 10
        """
        try:
            result = graph.query(query)
            return result if result else []
        except Exception:
            return []

    # LCELãƒã‚§ã‚¤ãƒ³æ§‹ç¯‰
    def retriever_and_merge(question: str):
        """ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ã‚°ãƒ©ãƒ•æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ¼ã‚¸"""
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        docs = vector_retriever.invoke(question)

        # ã‚°ãƒ©ãƒ•æ¤œç´¢
        triples = get_graph_context(question)

        graph_lines = [
            f"{t.get('start')} -[{t.get('type')}]â†’ {t.get('end')}"
            for t in triples
        ] if triples else ["(ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãªã—)"]

        context = (
            "<GRAPH_CONTEXT>\n" + "\n".join(graph_lines) + "\n</GRAPH_CONTEXT>\n\n" +
            "<DOCUMENT_CONTEXT>\n" + "\n---\n".join(d.page_content for d in docs) + "\n</DOCUMENT_CONTEXT>"
        )
        return {"context": context, "question": question}

    prompt = PromptTemplate.from_template(
        """ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚\nè³ªå•: {question}\n\n{context}\n\n---\nä¸Šè¨˜æƒ…å ±ã®ã¿ã‚’æ ¹æ‹ ã«ã€æ—¥æœ¬èªã§ç¶²ç¾…çš„ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
    )

    chain = (
        RunnablePassthrough()
        | RunnableLambda(retriever_and_merge)
        | prompt
        | AzureChatOpenAI(
            azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT,
            openai_api_version=AZURE_OPENAI_API_VERSION,
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            temperature=0
        )
        | StrOutputParser()
    )

    return chain, graph

# ã‚°ãƒ©ãƒ•å–å¾—é–¢æ•°ï¼ˆæ”¹å–„ç‰ˆï¼‰
def get_enhanced_graph_data(graph, limit=200):
    """Neo4jã‹ã‚‰æ‹¡å¼µã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã€æ¥ç¶šæ•°å«ã‚€ï¼‰"""
    query = f"""
    MATCH (n)-[r]->(m)
    WITH n, r, m, labels(n) as source_labels, labels(m) as target_labels
    RETURN
      n.id AS source,
      CASE WHEN size(source_labels) > 0 THEN source_labels[0] ELSE 'Unknown' END AS source_type,
      type(r) AS relation,
      m.id AS target,
      CASE WHEN size(target_labels) > 0 THEN target_labels[0] ELSE 'Unknown' END AS target_type,
      COUNT {{ (n)--() }} AS source_degree,
      COUNT {{ (m)--() }} AS target_degree
    LIMIT {limit}
    """
    result = graph.query(query)
    return result

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
def get_graph_data(graph):
    """Neo4jã‹ã‚‰ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    return get_enhanced_graph_data(graph, limit=100)

# ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—æ¨è«–é–¢æ•°
def get_node_type(node_name: str, node_label: str = None) -> str:
    """ãƒãƒ¼ãƒ‰åã‚„ãƒ©ãƒ™ãƒ«ã‹ã‚‰ã‚¿ã‚¤ãƒ—ã‚’æ¨è«–"""
    if node_label and node_label != 'Unknown':
        return node_label

    # äººç‰©åˆ¤å®š
    person_keywords = ['å¤ªéƒ', 'å§«', 'çˆº', 'å©†', 'ç‹', 'ä¾', 'äºº', 'è€…']
    if any(kw in node_name for kw in person_keywords):
        return 'Person'

    # å ´æ‰€åˆ¤å®š
    place_keywords = ['å±±', 'å·', 'å³¶', 'æ‘', 'åŸ', 'å›½', 'éƒ½', 'é‡Œ']
    if any(kw in node_name for kw in place_keywords):
        return 'Place'

    # ã‚¤ãƒ™ãƒ³ãƒˆåˆ¤å®š
    event_keywords = ['æˆ¦', 'æ—…', 'é€€æ²»', 'ç™ºè¦‹', 'èª•ç”Ÿ', 'å‡ºä¼š']
    if any(kw in node_name for kw in event_keywords):
        return 'Event'

    # ç‰©åˆ¤å®š
    object_keywords = ['å®', 'åˆ€', 'èˆ¹', 'ç‰', 'ç®±', 'é¡']
    if any(kw in node_name for kw in object_keywords):
        return 'Object'

    return 'Other'

# ã‚¿ã‚¤ãƒ—ã”ã¨ã®è‰²ã‚’è¿”ã™
def get_color_for_type(node_type: str) -> str:
    """ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè‰²ã‚’è¿”ã™"""
    color_map = {
        'Person': '#FF6B6B',      # èµ¤ç³»ï¼ˆäººç‰©ï¼‰
        'Place': '#4ECDC4',       # é’ç·‘ç³»ï¼ˆå ´æ‰€ï¼‰
        'Event': '#95E1D3',       # ç·‘ç³»ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆï¼‰
        'Object': '#FFE66D',      # é»„è‰²ç³»ï¼ˆç‰©ï¼‰
        'Organization': '#A8E6CF', # è–„ç·‘ï¼ˆçµ„ç¹”ï¼‰
        'Other': '#95A5A6',       # ã‚°ãƒ¬ãƒ¼ï¼ˆãã®ä»–ï¼‰
        'Unknown': '#7F8C8D'      # æ¿ƒã„ã‚°ãƒ¬ãƒ¼ï¼ˆä¸æ˜ï¼‰
    }
    return color_map.get(node_type, '#95A5A6')

# Streamlit-Agraphå¯è¦–åŒ–é–¢æ•°
def visualize_graph_agraph(graph_data):
    """Streamlit-Agraphã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«å¯è¦–åŒ–"""
    try:
        from streamlit_agraph import agraph, Node, Edge, Config

        nodes = []
        edges = []
        node_dict = {}

        # ãƒãƒ¼ãƒ‰åé›†ã¨ã‚¿ã‚¤ãƒ—åˆ¤å®š
        for item in graph_data:
            source_type = get_node_type(item['source'], item.get('source_type'))
            target_type = get_node_type(item['target'], item.get('target_type'))

            source_degree = item.get('source_degree', 1)
            target_degree = item.get('target_degree', 1)

            if item['source'] not in node_dict:
                node_dict[item['source']] = {
                    'type': source_type,
                    'degree': source_degree
                }

            if item['target'] not in node_dict:
                node_dict[item['target']] = {
                    'type': target_type,
                    'degree': target_degree
                }

        # ãƒãƒ¼ãƒ‰ä½œæˆï¼ˆã‚µã‚¤ã‚ºã‚’æ¥ç¶šæ•°ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        for node_id, node_info in node_dict.items():
            size = 10 + min(node_info['degree'] * 3, 50)  # æœ€å°10ã€æœ€å¤§60
            color = get_color_for_type(node_info['type'])
            nodes.append(
                Node(
                    id=node_id,
                    label=node_id,
                    size=size,
                    color=color,
                    title=f"{node_id} ({node_info['type']}, æ¥ç¶šæ•°: {node_info['degree']})"
                )
            )

        # ã‚¨ãƒƒã‚¸ä½œæˆ
        for item in graph_data:
            edges.append(
                Edge(
                    source=item['source'],
                    target=item['target'],
                    label=item['relation'],
                    color="#888888"
                )
            )

        # è¨­å®š
        config = Config(
            width="100%",
            height=700,
            directed=True,
            nodeHighlightBehavior=True,
            highlightColor="#F7B731",
            collapsible=True,
            node={'labelProperty': 'label'},
            link={'labelProperty': 'label', 'renderLabel': True}
        )

        return agraph(nodes=nodes, edges=edges, config=config)

    except ImportError:
        return None

# Pyviså¼·åŒ–ç‰ˆå¯è¦–åŒ–é–¢æ•°
def visualize_graph_pyvis_enhanced(graph_data):
    """Pyvisã§å¼·åŒ–ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–"""
    try:
        from pyvis.network import Network

        net = Network(
            height="700px",
            width="100%",
            bgcolor="#1a1a1a",
            font_color="white",
            notebook=False
        )

        # ç‰©ç†ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®š
        net.set_options("""
        {
          "physics": {
            "enabled": true,
            "barnesHut": {
              "gravitationalConstant": -8000,
              "springLength": 250,
              "springConstant": 0.001,
              "damping": 0.5
            },
            "minVelocity": 0.75
          },
          "nodes": {
            "font": {"size": 14, "face": "arial"},
            "borderWidth": 2,
            "borderWidthSelected": 4
          },
          "edges": {
            "color": {"inherit": "from"},
            "smooth": {"type": "continuous"},
            "font": {"size": 12, "align": "middle"}
          },
          "interaction": {
            "hover": true,
            "navigationButtons": true,
            "keyboard": true
          }
        }
        """)

        node_dict = {}

        # ãƒãƒ¼ãƒ‰æƒ…å ±åé›†
        for item in graph_data:
            source_type = get_node_type(item['source'], item.get('source_type'))
            target_type = get_node_type(item['target'], item.get('target_type'))

            source_degree = item.get('source_degree', 1)
            target_degree = item.get('target_degree', 1)

            if item['source'] not in node_dict:
                node_dict[item['source']] = {
                    'type': source_type,
                    'degree': source_degree,
                    'color': get_color_for_type(source_type)
                }

            if item['target'] not in node_dict:
                node_dict[item['target']] = {
                    'type': target_type,
                    'degree': target_degree,
                    'color': get_color_for_type(target_type)
                }

        # ãƒãƒ¼ãƒ‰è¿½åŠ 
        for node_id, node_info in node_dict.items():
            size = 15 + min(node_info['degree'] * 2, 40)
            net.add_node(
                node_id,
                label=node_id,
                color=node_info['color'],
                size=size,
                title=f"<b>{node_id}</b><br>ã‚¿ã‚¤ãƒ—: {node_info['type']}<br>æ¥ç¶šæ•°: {node_info['degree']}",
                borderWidth=2
            )

        # ã‚¨ãƒƒã‚¸è¿½åŠ 
        for item in graph_data:
            net.add_edge(
                item['source'],
                item['target'],
                label=item['relation'],
                title=item['relation'],
                arrows='to',
                color='#666666'
            )

        net.save_graph("graph_enhanced.html")
        with open("graph_enhanced.html", "r", encoding="utf-8") as f:
            html = f.read()
        return html

    except ImportError:
        return None

# æ—§ã‚°ãƒ©ãƒ•å¯è¦–åŒ–é–¢æ•°ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
def visualize_graph(graph_data):
    """pyvisã§ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    return visualize_graph_pyvis_enhanced(graph_data)

# ãƒ¡ã‚¤ãƒ³UI
st.header("ğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

# æ—¢å­˜ã‚°ãƒ©ãƒ•ã®ãƒã‚§ãƒƒã‚¯ï¼ˆåˆå›ã®ã¿ï¼‰
if not st.session_state.existing_graph_loaded and not st.session_state.initialized:
    try:
        temp_graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PW)
        graph_info = check_existing_graph(temp_graph)

        if graph_info['exists']:
            st.info(f"ğŸ“Š æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ: ãƒãƒ¼ãƒ‰ {graph_info['node_count']}å€‹ã€ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒƒãƒ— {graph_info['rel_count']}æœ¬")

            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ æ—¢å­˜ã‚°ãƒ©ãƒ•ã‚’èª­ã¿è¾¼ã‚€", type="primary"):
                    with st.spinner("æ—¢å­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚·ã‚¹ãƒ†ãƒ ã‚’å¾©å…ƒä¸­..."):
                        try:
                            st.session_state.chain, st.session_state.graph = restore_from_existing_graph()
                            st.session_state.initialized = True
                            st.session_state.existing_graph_loaded = True
                            st.success("âœ… æ—¢å­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰å¾©å…ƒå®Œäº†ï¼ã™ãã«è³ªå•ã§ãã¾ã™ã€‚")
                            st.rerun()
                        except Exception as e:
                            st.error(f"å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")

            with col2:
                if st.button("ğŸ—‘ï¸ æ—¢å­˜ã‚°ãƒ©ãƒ•ã‚’ã‚¯ãƒªã‚¢ã—ã¦æ–°è¦ä½œæˆ"):
                    with st.spinner("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ä¸­..."):
                        try:
                            temp_graph.query("MATCH (n) DETACH DELETE n")
                            st.session_state.existing_graph_loaded = True
                            st.success("âœ… ã‚¯ãƒªã‚¢å®Œäº†ã€‚æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ã‚¯ãƒªã‚¢ã‚¨ãƒ©ãƒ¼: {e}")

            st.markdown("---")
    except Exception as e:
        # Neo4jæ¥ç¶šã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆå¾Œç¶šã®å‡¦ç†ã§å¯¾å¿œï¼‰
        pass

uploaded_files = st.file_uploader(
    "PDF/ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["pdf", "txt"],
    accept_multiple_files=True,
    help="è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™"
)

if uploaded_files:
    st.success(f"âœ… {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
    with st.expander("ğŸ“„ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«"):
        for file in uploaded_files:
            st.write(f"- {file.name} ({file.size} bytes)")

    # ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•æ§‹ç¯‰ãƒœã‚¿ãƒ³
    if st.button("ğŸš€ ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰", type="primary"):
        with st.spinner("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ä¸­..."):
            try:
                text_content = load_documents(uploaded_files)
                st.info(f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text_content)} æ–‡å­—")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                st.stop()

        with st.spinner("ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­... (æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
            try:
                st.session_state.chain, st.session_state.graph = build_rag_system(text_content)
                st.session_state.initialized = True
                st.session_state.uploaded_files = [f.name for f in uploaded_files]
                st.success("âœ… ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•æ§‹ç¯‰å®Œäº†!")
            except Exception as e:
                st.error(f"æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                st.code(traceback.format_exc())

st.markdown("---")

col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ’¬ è³ªå•å…¥åŠ›")

    # è³ªå•å…¥åŠ›
    if st.session_state.initialized:
        question = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", height=100)

        if st.button("ğŸ” è³ªå•ã™ã‚‹"):
            if question:
                with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
                    try:
                        answer = st.session_state.chain.invoke(question)
                        st.markdown("### ğŸ“ å›ç­”")
                        st.markdown(answer)
                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        st.info("ã¾ãšRAGã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¦ãã ã•ã„")

with col2:
    st.header("ğŸ•¸ï¸ ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•")

    if st.session_state.initialized and show_graph:
        if st.button("ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º"):
            with st.spinner("ã‚°ãƒ©ãƒ•å–å¾—ä¸­..."):
                try:
                    # æ‹¡å¼µã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿å–å¾—
                    graph_data = get_enhanced_graph_data(st.session_state.graph, limit=max_nodes)

                    if graph_data:
                        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        filtered_data = []
                        for item in graph_data:
                            source_type = get_node_type(item['source'], item.get('source_type'))
                            target_type = get_node_type(item['target'], item.get('target_type'))

                            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
                            type_filters = {
                                'Person': filter_person,
                                'Place': filter_place,
                                'Event': filter_event,
                                'Object': filter_object,
                                'Other': filter_other
                            }

                            if type_filters.get(source_type, True) and type_filters.get(target_type, True):
                                filtered_data.append(item)

                        if not filtered_data:
                            st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        else:
                            # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
                            unique_nodes = set()
                            for item in filtered_data:
                                unique_nodes.add(item['source'])
                                unique_nodes.add(item['target'])

                            st.markdown(f"**çµ±è¨ˆæƒ…å ±:** ãƒãƒ¼ãƒ‰ {len(unique_nodes)}å€‹ / ã‚¨ãƒƒã‚¸ {len(filtered_data)}æœ¬")

                            # å¯è¦–åŒ–ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ
                            if "Agraph" in viz_engine:
                                # Streamlit-Agraphå¯è¦–åŒ–
                                result = visualize_graph_agraph(filtered_data)
                                if result is None:
                                    st.warning("Streamlit-AgraphãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚Pyvisã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
                                    html = visualize_graph_pyvis_enhanced(filtered_data)
                                    if html:
                                        st.components.v1.html(html, height=700)
                            else:
                                # Pyviså¯è¦–åŒ–
                                html = visualize_graph_pyvis_enhanced(filtered_data)
                                if html:
                                    st.components.v1.html(html, height=700)
                                else:
                                    st.warning("å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã—ã¾ã™ã€‚")
                                    st.dataframe(filtered_data)
                    else:
                        st.info("ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                    import traceback
                    st.code(traceback.format_exc())
    else:
        if not st.session_state.initialized:
            st.info("RAGã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã™ã‚‹ã¨ã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("**Graph-RAG Demo** | Powered by LangChain, Neo4j & PGVector")
